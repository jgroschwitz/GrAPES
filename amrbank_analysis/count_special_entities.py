import random
import re
from collections import Counter

from amrbank_analysis.vulcan_pickle_builder import VulcanPickleBuilder
from find_rare_node_labels import load_corpus_from_folder
from util import get_node_by_name


def main():
    training_corpus = load_corpus_from_folder("../../../data/Edinburgh/amr3.0/data/amrs/split/training/")
    print(len(training_corpus))
    test_corpus = load_corpus_from_folder("../../../data/Edinburgh/amr3.0/data/amrs/split/test/")
    print(len(test_corpus))

    r = random.Random(391)  # seed generated by random.org
    r.shuffle(test_corpus)

    training_label_counter = Counter()
    all_training_attributes = set()
    test_label_counter = Counter()

    training_attribute_dict = dict()
    training_filtered_label_counter = Counter()
    test_attribute_dict = dict()
    test_filtered_label_counter = Counter()
    test_unseen_attribute_dict = dict()
    test_unseen_label_counter = Counter()

    special_entity_labels = ["name", "data-entity", "percentage-entity", "phone-number-entity",
                             "email-address-entity", "url-entity", "byline-91", "correlate-91",
                             "course-91", "have-degree-of-resemblance-91", "hyperlink-91",
                             "instead-of-91", "publication-91", "request-confirmation-91", "score-entity",
                             "score-on-scale-91", "statistical-test-91", "street-address-91",
                             "string-entity", "value-interval", "variable"]

    for graph in training_corpus:
        extract_entities(graph, special_entity_labels, training_attribute_dict, training_filtered_label_counter,
                         training_label_counter, all_attributes=all_training_attributes)

    for graph in test_corpus:
        extract_entities(graph, special_entity_labels, test_attribute_dict, test_filtered_label_counter,
                         test_label_counter, seen=all_training_attributes, unseen_attribute_dict=test_unseen_attribute_dict,
                         unseen_label_counter=test_unseen_label_counter)

    with open("outputs/special_entities.txt", "w") as f:
        for label, counter in training_label_counter.most_common():
            f.write(label+f"\t\t{str(counter)}\n")

    with open("outputs/special_entities_test.txt", "w") as f:
        for label, counter in test_label_counter.most_common():
            f.write(label+f"\t\t{str(counter)}\n")

    with open("outputs/special_entities_attributes.txt", "w") as f:
        write_attributes(f, training_attribute_dict, training_filtered_label_counter)

    with open("outputs/special_entities_attributes_test.txt", "w") as f:
        write_attributes(f, test_attribute_dict, test_filtered_label_counter)

    with open("outputs/special_entities_attributes_test_unseen.txt", "w") as f:
        write_attributes(f, test_unseen_attribute_dict, test_unseen_label_counter)

    seen_vulcan_pickle_builder = VulcanPickleBuilder()
    unseen_vulcan_pickle_builder = VulcanPickleBuilder()
    with open("../corpus/unseen_special_entities.tsv", "w") as f:
        with open("../corpus/seen_special_entities.tsv", "w") as g:
            for graph in test_corpus:
                for attribute in graph.attributes():
                    parent = get_node_by_name(attribute[0], graph)
                    if parent.target in special_entity_labels or is_interesting_number(attribute[2]):
                        if not parent.target == "name" and not parent.target == "date-entity":
                            if attribute[2] not in all_training_attributes:
                                f.write(f"{graph.metadata['id']}\t{parent.target}\t{attribute[1]}\t{attribute[2]}\n")
                                unseen_vulcan_pickle_builder.add_graph(graph)
                                unseen_vulcan_pickle_builder.add_graph_highlight([parent.source])
                            else:
                                g.write(f"{graph.metadata['id']}\t{parent.target}\t{attribute[1]}\t{attribute[2]}\n")
                                seen_vulcan_pickle_builder.add_graph(graph)
                                seen_vulcan_pickle_builder.add_graph_highlight([parent.source])

    unseen_vulcan_pickle_builder.save_pickle("outputs/unseen_special_entities.pickle")
    seen_vulcan_pickle_builder.save_pickle("outputs/seen_special_entities.pickle")


def write_attributes(f, training_attribute_dict, training_filtered_label_counter):
    labels = list(training_attribute_dict.keys())
    labels.sort(key=lambda x: training_filtered_label_counter[x], reverse=True)
    for label in labels:
        edge2set = training_attribute_dict[label]
        f.write(f"{label} ({training_filtered_label_counter[label]}):\n")
        for edge in get_keys_sorted_by_length_inside(edge2set):
            values = edge2set[edge]
            f.write(f"\t{edge} ({len(values)}):\n")
            max_length = min(len(values), 10)
            for value in values[:max_length]:
                f.write("\t\t" + value + "\n")
            f.write("\n")
        f.write("\n\n")


def extract_entities(graph, special_entity_labels, attribute_dict, label_counter, unfiltered_label_counter,
                     all_attributes=None, seen=None, unseen_attribute_dict=None, unseen_label_counter=None):
    for instance in graph.instances():
        #  simple, overmatching version:
        if "-entity" in instance.target or "-91" in instance.target or "-interval" in instance.target \
                or "-quantity" in instance.target \
                or instance.target == "variable":
            unfiltered_label_counter[instance.target] += 1
    # store attributes
    for attribute in graph.attributes():
        parent = get_node_by_name(attribute[0], graph)
        if parent.target in special_entity_labels or is_interesting_number(attribute[2]):
            edge2set = attribute_dict.setdefault(parent.target, dict())
            edge2set.setdefault(attribute[1], []).append(attribute[2])
            label_counter[parent.target] += 1
            if all_attributes is not None:
                all_attributes.add(attribute[2])
            if seen is not None and attribute[2] not in seen:
                edge2set_unseen = unseen_attribute_dict.setdefault(parent.target, dict())
                edge2set_unseen.setdefault(attribute[1], []).append(attribute[2])
                unseen_label_counter[parent.target] += 1


def get_keys_sorted_by_length_inside(dictionary):
    keys = list(dictionary.keys())
    keys.sort(key=lambda x: len(dictionary[x]), reverse=True)
    return keys


def is_interesting_number(string):
    return re.match(r"[0-9]+", string) and len(string) > 1 and not re.match(r"10+", string)


if __name__ == "__main__":
    main()
